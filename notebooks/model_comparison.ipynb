{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score, confusion_matrix, roc_curve, accuracy_score, auc, roc_auc_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 3,
   "source": [
    "Loading PCA data and splitting to train and evaluation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/processed/mushrooms_pca.csv')\n",
    "y = data['class']\n",
    "X = data.drop('class', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y.ravel(), test_size=.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 3,
   "source": [
    "Grid search - best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(clf, tuned_parameters, scoring='f1',\n",
    "                           cv=10, return_train_score=True, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 3,
   "source": [
    "Best model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllrr}\n\\toprule\n{} & param\\_kernel & param\\_coef0 & param\\_C &  mean\\_test\\_score &  mean\\_fit\\_time \\\\\n\\midrule\n0 &       linear &         NaN &       1 &         0.857536 &       4.923426 \\\\\n1 &       linear &         NaN &    0.01 &         0.853436 &       3.529057 \\\\\n2 &       linear &         NaN &     0.1 &         0.853145 &       3.212004 \\\\\n3 &          rbf &         NaN &       1 &         0.844371 &       5.537084 \\\\\n4 &         poly &         0.5 &     0.1 &         0.834283 &       6.544490 \\\\\n5 &         poly &         0.5 &     0.1 &         0.824538 &       6.869619 \\\\\n6 &          rbf &         NaN &       1 &         0.634898 &       8.441214 \\\\\n7 &          rbf &         NaN &     0.1 &         0.611424 &       8.392245 \\\\\n\\bottomrule\n\\end{tabular}\n\n"
     ]
    }
   ],
   "source": [
    "res=pd.DataFrame(grid_search.cv_results_).sort_values('rank_test_score').reset_index(drop=True)\n",
    "res = res[['param_kernel', 'param_coef0', 'param_C', 'mean_test_score', 'mean_fit_time']]\n",
    "print(res.head(n=8).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'kernel': 'linear'}\n              precision    recall  f1-score   support\n\n           0       0.87      0.88      0.88       843\n           1       0.87      0.85      0.86       782\n\n   micro avg       0.87      0.87      0.87      1625\n   macro avg       0.87      0.87      0.87      1625\nweighted avg       0.87      0.87      0.87      1625\n\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(grid_search, open(\"models/svm.p\", \"wb\" ) )\n",
    "y_true, y_pred = y_test, grid_search.predict(X_test)\n",
    "grid_search\n",
    "print(grid_search.best_params_)\n",
    "report = classification_report(y_true, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[773,  70],\n       [ 78, 704]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 3,
   "source": [
    "Grid Search detailed results for each params configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9b16a8cea3f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_latex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_search' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)\n",
    "print(pd.DataFrame(grid_search.cv_results_).to_latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 3,
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Desktop\\kto_ma_szkole_ten_ma_lzej\\Erasm\\mushrooms\\venv\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n       hidden_layer_sizes=(100,), learning_rate='constant',\n       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n       validation_fraction=0.1, verbose=False, warm_start=False),\n       fit_params=None, iid='warn', n_jobs=3,\n       param_grid=[{'hidden_layer_sizes': [(30,), (50,), (50, 10), (100, 10, 10)], 'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10], 'max_iter': range(50, 200, 50)}],\n       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier()\n",
    "\n",
    "grid_search_nn = GridSearchCV(clf, nn_tuned_parameters, scoring='f1',\n",
    "                           cv=10, return_train_score=True, n_jobs=3)\n",
    "grid_search_nn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1, 'hidden_layer_sizes': (50,), 'max_iter': 100}\n              precision    recall  f1-score   support\n\n           0       0.91      0.92      0.91       843\n           1       0.91      0.90      0.90       782\n\n   micro avg       0.91      0.91      0.91      1625\n   macro avg       0.91      0.91      0.91      1625\nweighted avg       0.91      0.91      0.91      1625\n\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = y_test, grid_search_nn.predict(X_test)\n",
    "print(grid_search_nn.best_params_)\n",
    "report = classification_report(y_true, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllrr}\n\\toprule\n{} & param\\_hidden\\_layer\\_sizes & param\\_alpha & param\\_max\\_iter &  mean\\_test\\_score &  mean\\_fit\\_time \\\\\n\\midrule\n0 &                    (50,) &         0.1 &            100 &         0.901093 &       5.726179 \\\\\n1 &                 (50, 10) &           1 &             50 &         0.899865 &       3.047146 \\\\\n2 &                    (50,) &         0.1 &             50 &         0.899273 &       2.809682 \\\\\n3 &                    (50,) &        0.01 &             50 &         0.899199 &       3.005558 \\\\\n4 &                 (50, 10) &           1 &            150 &         0.899135 &       8.787189 \\\\\n5 &            (100, 10, 10) &           1 &             50 &         0.898126 &       4.338791 \\\\\n6 &                    (50,) &      0.0001 &             50 &         0.897904 &       3.261373 \\\\\n7 &                    (50,) &         0.1 &            150 &         0.897216 &       8.286927 \\\\\n\\bottomrule\n\\end{tabular}\n\n"
     ]
    }
   ],
   "source": [
    "res=pd.DataFrame(grid_search_nn.cv_results_).sort_values('rank_test_score').reset_index(drop=True)\n",
    "res = res[['param_hidden_layer_sizes', 'param_alpha', 'param_max_iter', 'mean_test_score', 'mean_fit_time']]\n",
    "print(res.head(n=8).to_latex())\n",
    "pickle.dump(grid_search_nn, open(\"models/nn.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   param_hidden_layer_sizes param_alpha param_max_iter  mean_test_score  \\\n0                     (50,)         0.1            100         0.901093   \n23                    (30,)         0.1            100         0.893007   \n26                 (50, 10)         0.1            100         0.892127   \n45            (100, 10, 10)         0.1            100         0.888268   \n\n    mean_fit_time  \n0        5.726179  \n23       4.458571  \n26       6.274711  \n45       9.023557  \n"
     ]
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1scores = res_alpha['mean_test_score']\n",
    "plt.plot(res_alpha['param_alpha'], f1scores)\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('f1 score')\n",
    "plt.title('MLP classifier performance')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
